{"cells":[{"cell_type":"markdown","source":["##TSWA Practical 6 - Text Preprocessing and Normalization"],"metadata":{"id":"Ze_uak4_F7Rs"}},{"cell_type":"code","source":["import nltk"],"metadata":{"id":"NGandzC7G5dP","executionInfo":{"status":"ok","timestamp":1719498940960,"user_tz":-330,"elapsed":4266,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":742,"status":"ok","timestamp":1719498941697,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"YXcrjbIkXe92","outputId":"68c8344a-fe77-43be-83d2-8b588fb82263"},"outputs":[{"output_type":"stream","name":"stdout","text":["b': -4em;\\r\\n    margin-left: 4em;\\r\\n    margin-top: 1em;\\r\\n    margin-bottom: 0;\\r\\n    font-size: medium\\r\\n}\\r\\n#pg-header #pg-header-authlist {\\r\\n    all: initial;\\r\\n    margin-top: 0;\\r\\n    margin-bottom: 0;\\r\\n}\\r\\n#pg-header #pg-machine-header strong {\\r\\n    font-weight: normal;\\r\\n}\\r\\n#pg-header #pg-start-separator, #pg-footer #pg-end-separator {\\r\\n    margin-bottom: 3em;\\r\\n    margin-left: 0;\\r\\n    margin-right: auto;\\r\\n    margin-top: 2em;\\r\\n    text-align: center\\r\\n}\\r\\n\\r\\n    .xhtml_center {text-align: center; display: block;}\\r\\n    .xhtml_center table {\\r\\n        display: table;\\r\\n        text-align: left;\\r\\n        margin-left: auto;\\r\\n        margin-right: auto;\\r\\n        }</style><title>The Project Gutenberg eBook of The Bible, King James version, Book 1: Genesis, by Anonymous</title><style>/* ************************************************************************\\r\\n * classless css copied from https://www.pgdp.net/wiki/CSS_Cookbook/Styles\\r\\n * ********************************************************************** */\\r\\n/* ************************************************************************\\r\\n * set the body margins to allow whitespace along sides of window\\r\\n * ******************************************'\n"]}],"source":["import requests\n","data = requests.get('http://www.gutenberg.org/cache/epub/8001/pg8001.html')\n","content = data.content\n","print(content[1000:2200])"]},{"cell_type":"markdown","source":["#### 1-Removing HTML Tags. Import re"],"metadata":{"id":"wv8777DAHBK4"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"txZz7Ov3Xp93","executionInfo":{"status":"ok","timestamp":1719498941698,"user_tz":-330,"elapsed":5,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["import re"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"tbkwZChhXr-D","executionInfo":{"status":"ok","timestamp":1719498942229,"user_tz":-330,"elapsed":535,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["from bs4 import BeautifulSoup"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"VFVLcAi0XvDh","executionInfo":{"status":"ok","timestamp":1719498942230,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["def html_stripping(text):\n","  soup = BeautifulSoup(text, \"html.parser\")\n","  [s.extract() for s in soup(['iframe', 'script'])]\n","  stripped_text = soup.get_text()\n","  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n","  return stripped_text"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":580,"status":"ok","timestamp":1719498942805,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"IZzku6XSX13l","outputId":"1d29e525-5d1f-4486-c704-fd80c05d5044"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Book 01        Genesis\n","01:001:001 In the beginning God created the heaven and the earth.\n","01:001:002 And the earth was without form, and void; and darkness was\n","           upon the face of the deep. And the Spirit of God moved upon\n","           the face of the waters.\n","01:001:003 And God said, Let there be light: and there was light.\n","01:001:004 And God saw the light, that it was good: and God divided the\n","           light from the darkness.\n","01:001:005 And God called the light Day, and the darkness he called\n","           Night. And the evening and the morning were the first day.\n","01:001:006 And God said, Let there be a firmament in the midst of the\n","           waters, and let it divide the waters from the waters.\n","01:001:007 And God made the firmament, and divided the waters which were\n","           under the firmament from the waters which were above the\n","           firmament: and it was so.\n","01:001:008 And God called the firmament Heaven. And the evening and the\n","           morning were the second day.\n","01:001\n"]}],"source":["clean_content = html_stripping(content)\n","print(clean_content[1036:2045])"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"MYS-xvoJX4V6","executionInfo":{"status":"ok","timestamp":1719498942805,"user_tz":-330,"elapsed":4,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["import nltk\n","from nltk.corpus import gutenberg\n","from pprint import pprint\n","import numpy as np"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nEE2rkFYE80","outputId":"6ece383e-5a2f-4167-f923-d8dee00dcd0d","executionInfo":{"status":"ok","timestamp":1719498998730,"user_tz":-330,"elapsed":55929,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pe08.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}],"source":["nltk.download('all')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1719498998731,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"I9qtzlaKfKDK","outputId":"10fda839-c12e-48db-fa2b-326a12c88d0c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["nltk.download('punkt')\n","import re\n","import string\n","from pprint import pprint"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"yM2r-aFzUo0x","executionInfo":{"status":"ok","timestamp":1719498998732,"user_tz":-330,"elapsed":47,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["# Creating our own corpus\n","corpus=[\"The brown fox wasn't quick and he couldn't win the race.\",\n","\"Hey it was a great cricket match @yesterday!!\",\n","\"I just bought a @new mobile for me at $1000.\",\n","\"Python NLP is really ****amazing*****!!@@@\"]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"pN-datxmpgeB","executionInfo":{"status":"ok","timestamp":1719498998733,"user_tz":-330,"elapsed":48,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["def tokenize_text(text):\n","  sentences=nltk.sent_tokenize(text)\n","  print(sentences)\n","  word_tokens=[nltk.word_tokenize(sentence) for sentence in sentences]\n","  return word_tokens"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1719498998733,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"RmNp78CMpl-T","outputId":"0ac7b56c-e62b-4f35-f2c0-aeb19ca2d14e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[\"The brown fox wasn't quick and he couldn't win the race.\"]\n","['Hey it was a great cricket match @yesterday!', '!']\n","['I just bought a @new mobile for me at $1000.']\n","['Python NLP is really ****amazing*****!!', '@@@']\n","[[['The', 'brown', 'fox', 'was', \"n't\", 'quick', 'and', 'he', 'could', \"n't\", 'win', 'the', 'race', '.']], [['Hey', 'it', 'was', 'a', 'great', 'cricket', 'match', '@', 'yesterday', '!'], ['!']], [['I', 'just', 'bought', 'a', '@', 'new', 'mobile', 'for', 'me', 'at', '$', '1000', '.']], [['Python', 'NLP', 'is', 'really', '*', '*', '*', '*', 'amazing', '*', '*', '*', '*', '*', '!', '!'], ['@', '@', '@']]]\n"]}],"source":["# Get the token list from the above def\n","token_list=[tokenize_text(text) for text in corpus]\n","print(token_list)"]},{"cell_type":"markdown","source":["### 2 - Removing special characters"],"metadata":{"id":"EYbxtX41HFto"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"e2clNxxTZA7d","executionInfo":{"status":"ok","timestamp":1719498998733,"user_tz":-330,"elapsed":44,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["def remove_special_characters(sentence,keep_apostrophes=False):\n","  sentence = sentence.strip()\n","  if keep_apostrophes:\n","    PATTERN = r'[?|$|&|*|%|@|(|)|~]' # add other characters here to remove them\n","    filtered_sentence = re.sub(PATTERN, r'', sentence)\n","  else:\n","    PATTERN = r'[^a-zA-Z0-9 ]' # only extract alpha-numeric characters\n","    filtered_sentence = re.sub(PATTERN, r'', sentence)\n","  return filtered_sentence"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"g9D5mNkhr3LN","executionInfo":{"status":"ok","timestamp":1719498998734,"user_tz":-330,"elapsed":44,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["sentence=\"The brown fox wasn't quick and he couldn't win the race.\""]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1719498998734,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"vmqq49HQoM-a","outputId":"4c4742cc-9be0-4872-c6a4-dfd8a757735f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The brown fox wasnt quick and he couldnt win the race'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["remove_special_characters(sentence,keep_apostrophes=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9537,"status":"ok","timestamp":1719499008255,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"PwJprYHEZlNu","outputId":"16f750b8-e4e4-40d9-de0a-4cb312dd6444"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Collecting textsearch>=0.0.21 (from contractions)\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Collecting anyascii (from textsearch>=0.0.21->contractions)\n","  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n","  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"]}],"source":["!pip install contractions"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"hmr81PCkZp8z","executionInfo":{"status":"ok","timestamp":1719499008256,"user_tz":-330,"elapsed":50,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["import contractions"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1719499008256,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"SJNuqzySZtWj","outputId":"c1d420b1-7597-492b-d739-d669088476c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\"I'm\": 'I am', \"I'm'a\": 'I am about to', \"I'm'o\": 'I am going to', \"I've\": 'I have', \"I'll\": 'I will', \"I'll've\": 'I will have', \"I'd\": 'I would', \"I'd've\": 'I would have', 'Whatcha': 'What are you', \"amn't\": 'am not', \"ain't\": 'are not', \"aren't\": 'are not', \"'cause\": 'because', \"can't\": 'cannot', \"can't've\": 'cannot have', \"could've\": 'could have', \"couldn't\": 'could not', \"couldn't've\": 'could not have', \"daren't\": 'dare not', \"daresn't\": 'dare not', \"dasn't\": 'dare not', \"didn't\": 'did not', 'didn’t': 'did not', \"don't\": 'do not', 'don’t': 'do not', \"doesn't\": 'does not', \"e'er\": 'ever', \"everyone's\": 'everyone is', 'finna': 'fixing to', 'gimme': 'give me', \"gon't\": 'go not', 'gonna': 'going to', 'gotta': 'got to', \"hadn't\": 'had not', \"hadn't've\": 'had not have', \"hasn't\": 'has not', \"haven't\": 'have not', \"he've\": 'he have', \"he's\": 'he is', \"he'll\": 'he will', \"he'll've\": 'he will have', \"he'd\": 'he would', \"he'd've\": 'he would have', \"here's\": 'here is', \"how're\": 'how are', \"how'd\": 'how did', \"how'd'y\": 'how do you', \"how's\": 'how is', \"how'll\": 'how will', \"isn't\": 'is not', \"it's\": 'it is', \"'tis\": 'it is', \"'twas\": 'it was', \"it'll\": 'it will', \"it'll've\": 'it will have', \"it'd\": 'it would', \"it'd've\": 'it would have', 'kinda': 'kind of', \"let's\": 'let us', 'luv': 'love', \"ma'am\": 'madam', \"may've\": 'may have', \"mayn't\": 'may not', \"might've\": 'might have', \"mightn't\": 'might not', \"mightn't've\": 'might not have', \"must've\": 'must have', \"mustn't\": 'must not', \"mustn't've\": 'must not have', \"needn't\": 'need not', \"needn't've\": 'need not have', \"ne'er\": 'never', \"o'\": 'of', \"o'clock\": 'of the clock', \"ol'\": 'old', \"oughtn't\": 'ought not', \"oughtn't've\": 'ought not have', \"o'er\": 'over', \"shan't\": 'shall not', \"sha'n't\": 'shall not', \"shalln't\": 'shall not', \"shan't've\": 'shall not have', \"she's\": 'she is', \"she'll\": 'she will', \"she'd\": 'she would', \"she'd've\": 'she would have', \"should've\": 'should have', \"shouldn't\": 'should not', \"shouldn't've\": 'should not have', \"so've\": 'so have', \"so's\": 'so is', \"somebody's\": 'somebody is', \"someone's\": 'someone is', \"something's\": 'something is', 'sux': 'sucks', \"that're\": 'that are', \"that's\": 'that is', \"that'll\": 'that will', \"that'd\": 'that would', \"that'd've\": 'that would have', \"'em\": 'them', \"there're\": 'there are', \"there's\": 'there is', \"there'll\": 'there will', \"there'd\": 'there would', \"there'd've\": 'there would have', \"these're\": 'these are', \"they're\": 'they are', \"they've\": 'they have', \"they'll\": 'they will', \"they'll've\": 'they will have', \"they'd\": 'they would', \"they'd've\": 'they would have', \"this's\": 'this is', \"this'll\": 'this will', \"this'd\": 'this would', \"those're\": 'those are', \"to've\": 'to have', 'wanna': 'want to', \"wasn't\": 'was not', \"we're\": 'we are', \"we've\": 'we have', \"we'll\": 'we will', \"we'll've\": 'we will have', \"we'd\": 'we would', \"we'd've\": 'we would have', \"weren't\": 'were not', \"what're\": 'what are', \"what'd\": 'what did', \"what've\": 'what have', \"what's\": 'what is', \"what'll\": 'what will', \"what'll've\": 'what will have', \"when've\": 'when have', \"when's\": 'when is', \"where're\": 'where are', \"where'd\": 'where did', \"where've\": 'where have', \"where's\": 'where is', \"which's\": 'which is', \"who're\": 'who are', \"who've\": 'who have', \"who's\": 'who is', \"who'll\": 'who will', \"who'll've\": 'who will have', \"who'd\": 'who would', \"who'd've\": 'who would have', \"why're\": 'why are', \"why'd\": 'why did', \"why've\": 'why have', \"why's\": 'why is', \"will've\": 'will have', \"won't\": 'will not', \"won't've\": 'will not have', \"would've\": 'would have', \"wouldn't\": 'would not', \"wouldn't've\": 'would not have', \"y'all\": 'you all', \"y'all're\": 'you all are', \"y'all've\": 'you all have', \"y'all'd\": 'you all would', \"y'all'd've\": 'you all would have', \"you're\": 'you are', \"you've\": 'you have', \"you'll've\": 'you shall have', \"you'll\": 'you will', \"you'd\": 'you would', \"you'd've\": 'you would have', 'to cause': 'to cause', 'will cause': 'will cause', 'should cause': 'should cause', 'would cause': 'would cause', 'can cause': 'can cause', 'could cause': 'could cause', 'must cause': 'must cause', 'might cause': 'might cause', 'shall cause': 'shall cause', 'may cause': 'may cause', 'jan.': 'january', 'feb.': 'february', 'mar.': 'march', 'apr.': 'april', 'jun.': 'june', 'jul.': 'july', 'aug.': 'august', 'sep.': 'september', 'oct.': 'october', 'nov.': 'november', 'dec.': 'december', 'I’m': 'I am', 'I’m’a': 'I am about to', 'I’m’o': 'I am going to', 'I’ve': 'I have', 'I’ll': 'I will', 'I’ll’ve': 'I will have', 'I’d': 'I would', 'I’d’ve': 'I would have', 'amn’t': 'am not', 'ain’t': 'are not', 'aren’t': 'are not', '’cause': 'because', 'can’t': 'cannot', 'can’t’ve': 'cannot have', 'could’ve': 'could have', 'couldn’t': 'could not', 'couldn’t’ve': 'could not have', 'daren’t': 'dare not', 'daresn’t': 'dare not', 'dasn’t': 'dare not', 'doesn’t': 'does not', 'e’er': 'ever', 'everyone’s': 'everyone is', 'gon’t': 'go not', 'hadn’t': 'had not', 'hadn’t’ve': 'had not have', 'hasn’t': 'has not', 'haven’t': 'have not', 'he’ve': 'he have', 'he’s': 'he is', 'he’ll': 'he will', 'he’ll’ve': 'he will have', 'he’d': 'he would', 'he’d’ve': 'he would have', 'here’s': 'here is', 'how’re': 'how are', 'how’d': 'how did', 'how’d’y': 'how do you', 'how’s': 'how is', 'how’ll': 'how will', 'isn’t': 'is not', 'it’s': 'it is', '’tis': 'it is', '’twas': 'it was', 'it’ll': 'it will', 'it’ll’ve': 'it will have', 'it’d': 'it would', 'it’d’ve': 'it would have', 'let’s': 'let us', 'ma’am': 'madam', 'may’ve': 'may have', 'mayn’t': 'may not', 'might’ve': 'might have', 'mightn’t': 'might not', 'mightn’t’ve': 'might not have', 'must’ve': 'must have', 'mustn’t': 'must not', 'mustn’t’ve': 'must not have', 'needn’t': 'need not', 'needn’t’ve': 'need not have', 'ne’er': 'never', 'o’': 'of', 'o’clock': 'of the clock', 'ol’': 'old', 'oughtn’t': 'ought not', 'oughtn’t’ve': 'ought not have', 'o’er': 'over', 'shan’t': 'shall not', 'sha’n’t': 'shall not', 'shalln’t': 'shall not', 'shan’t’ve': 'shall not have', 'she’s': 'she is', 'she’ll': 'she will', 'she’d': 'she would', 'she’d’ve': 'she would have', 'should’ve': 'should have', 'shouldn’t': 'should not', 'shouldn’t’ve': 'should not have', 'so’ve': 'so have', 'so’s': 'so is', 'somebody’s': 'somebody is', 'someone’s': 'someone is', 'something’s': 'something is', 'that’re': 'that are', 'that’s': 'that is', 'that’ll': 'that will', 'that’d': 'that would', 'that’d’ve': 'that would have', '’em': 'them', 'there’re': 'there are', 'there’s': 'there is', 'there’ll': 'there will', 'there’d': 'there would', 'there’d’ve': 'there would have', 'these’re': 'these are', 'they’re': 'they are', 'they’ve': 'they have', 'they’ll': 'they will', 'they’ll’ve': 'they will have', 'they’d': 'they would', 'they’d’ve': 'they would have', 'this’s': 'this is', 'this’ll': 'this will', 'this’d': 'this would', 'those’re': 'those are', 'to’ve': 'to have', 'wasn’t': 'was not', 'we’re': 'we are', 'we’ve': 'we have', 'we’ll': 'we will', 'we’ll’ve': 'we will have', 'we’d': 'we would', 'we’d’ve': 'we would have', 'weren’t': 'were not', 'what’re': 'what are', 'what’d': 'what did', 'what’ve': 'what have', 'what’s': 'what is', 'what’ll': 'what will', 'what’ll’ve': 'what will have', 'when’ve': 'when have', 'when’s': 'when is', 'where’re': 'where are', 'where’d': 'where did', 'where’ve': 'where have', 'where’s': 'where is', 'which’s': 'which is', 'who’re': 'who are', 'who’ve': 'who have', 'who’s': 'who is', 'who’ll': 'who will', 'who’ll’ve': 'who will have', 'who’d': 'who would', 'who’d’ve': 'who would have', 'why’re': 'why are', 'why’d': 'why did', 'why’ve': 'why have', 'why’s': 'why is', 'will’ve': 'will have', 'won’t': 'will not', 'won’t’ve': 'will not have', 'would’ve': 'would have', 'wouldn’t': 'would not', 'wouldn’t’ve': 'would not have', 'y’all': 'you all', 'y’all’re': 'you all are', 'y’all’ve': 'you all have', 'y’all’d': 'you all would', 'y’all’d’ve': 'you all would have', 'you’re': 'you are', 'you’ve': 'you have', 'you’ll’ve': 'you shall have', 'you’ll': 'you will', 'you’d': 'you would', 'you’d’ve': 'you would have'}\n"]}],"source":["contraction_mapping=contractions.contractions_dict\n","print(contraction_mapping)"]},{"cell_type":"markdown","source":["### 3-Replacing contractions with expanded form"],"metadata":{"id":"uuje7uGxHKbz"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"Ua7EsEXlZzq0","executionInfo":{"status":"ok","timestamp":1719499008257,"user_tz":-330,"elapsed":39,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["def contraction_expansion(sentence,contraction_mapping):\n","  contractions_pattern=re.compile('({})'.format('|'.join(contraction_mapping.keys())),flags=re.IGNORECASE|re.DOTALL)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"C8XZSoyhcFcx","executionInfo":{"status":"ok","timestamp":1719499008257,"user_tz":-330,"elapsed":38,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["# To remove the accented characters\n","import unicodedata"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Y_1fdW76cIXi","executionInfo":{"status":"ok","timestamp":1719499008257,"user_tz":-330,"elapsed":37,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["# def for removing accented characters\n","def accented_char_removal(text):\n","  text=str(text)\n","  text = unicodedata.normalize('NFKD',text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n","  return text"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1719499008257,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"RKcTwbxqglKm","outputId":"279901a6-b7fd-49fb-e224-57e9fe75f380"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Some Accented text'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}],"source":["accented_char_removal('Sómě Áccěntěd těxt')"]},{"cell_type":"markdown","source":["###4 - Special Character Removal"],"metadata":{"id":"IayMdwo_HQgX"}},{"cell_type":"code","execution_count":23,"metadata":{"id":"FNdqndd4cVca","executionInfo":{"status":"ok","timestamp":1719499008258,"user_tz":-330,"elapsed":36,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["def special_char_removal(text, remove_digits=False):\n","  pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n","  text = re.sub(pattern, '', text)\n","  return text"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1719499008258,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"54-bsBQ4csCt","outputId":"21fb84b0-59b2-42de-fd4a-be207e0a9079"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Well this was fun What do you think '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}],"source":["special_char_removal(\"Well this was fun! What do you think? 123#@!\",remove_digits=True)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"_9at4lqedDh_","executionInfo":{"status":"ok","timestamp":1719499008258,"user_tz":-330,"elapsed":34,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["# 4_ Stemming\n","from nltk.stem import PorterStemmer"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"OtHzyHZ3dE_p","executionInfo":{"status":"ok","timestamp":1719499008259,"user_tz":-330,"elapsed":34,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["ps = PorterStemmer()"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1719499008259,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"EUvJvrZFdHn3","outputId":"73dd1b63-b2c2-4d43-bf86-181213fb45c2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('jump', 'jump', 'jump')"]},"metadata":{},"execution_count":27}],"source":["ps.stem('jumping'), ps.stem('jumps'), ps.stem('jumped')"]},{"cell_type":"markdown","source":["###5- Stemming"],"metadata":{"id":"ZkXfbkKsHTwi"}},{"cell_type":"code","execution_count":28,"metadata":{"id":"ppRPojcadL96","executionInfo":{"status":"ok","timestamp":1719499008260,"user_tz":-330,"elapsed":28,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["def simple_stemmer(text):\n","  ps = nltk.porter.PorterStemmer()\n","  text = ' '.join([ps.stem(word) for word in text.split()])\n","  return text"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1719499008260,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"mRBFzanZdZW5","outputId":"014216cb-4fae-4c4b-9ec8-83d800696458"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'my system keep crash hi crash yesterday, our crash daili'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}],"source":["simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"]},{"cell_type":"markdown","source":["### 6 - Lemmetization"],"metadata":{"id":"phH-56_DHY22"}},{"cell_type":"code","execution_count":30,"metadata":{"id":"l_iQtRo9dflc","executionInfo":{"status":"ok","timestamp":1719499008261,"user_tz":-330,"elapsed":28,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["from nltk.stem import WordNetLemmatizer"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"M96vY_JodmMc","executionInfo":{"status":"ok","timestamp":1719499008261,"user_tz":-330,"elapsed":27,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["wnl = WordNetLemmatizer()"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1718,"status":"ok","timestamp":1719499009952,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"qY8WdKJ7dufO","outputId":"c78950d3-690a-4402-85bf-0d7e90bbbfe8"},"outputs":[{"output_type":"stream","name":"stdout","text":["car\n","men\n"]}],"source":["# lemmatize nouns with 'n'\n","print(wnl.lemmatize('cars', 'n')) # s is removed\n","print(wnl.lemmatize('men', 'n'))"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1719499009953,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"qF_2TuZ9dzjp","outputId":"6088b09b-b3dd-401c-f629-1b185a3ad36a"},"outputs":[{"output_type":"stream","name":"stdout","text":["run\n","eat\n"]}],"source":["# lemmatize verbs with 'v'\n","print(wnl.lemmatize('running', 'v')) # extracting the verb from the verb phrase - running\n","print(wnl.lemmatize('ate', 'v')) # verb behind ate"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1719499009953,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"hE_Jt2mWd6Ol","outputId":"8d3e4c6b-bc4f-4fc4-e94c-4fc65295c7c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["sad\n","fancy\n"]}],"source":["# lemmatize adjectives with 'a'\n","print(wnl.lemmatize('saddest', 'a')) # orginal adjective extracted\n","print(wnl.lemmatize('fancier', 'a'))"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"baxyrdfceFaK","executionInfo":{"status":"ok","timestamp":1719499020416,"user_tz":-330,"elapsed":10469,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["# 6 - def for lemmatization\n","import spacy"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"dU0s-o1wenRG","executionInfo":{"status":"ok","timestamp":1719499022615,"user_tz":-330,"elapsed":2220,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["nlp = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"KLmuD1Qbe_Ly","executionInfo":{"status":"ok","timestamp":1719499022616,"user_tz":-330,"elapsed":28,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["# 5 - def for lemmatization\n","def text_lemmatization(text):\n","  text = nlp(text)\n","  text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n","  return text"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1719499022616,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"j-2VvlfqfM3n","outputId":"bc3ddd53-3116-44ea-a9e5-6dc3538ce4a3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'my system keep crash ! his crashed yesterday , ours crash daily'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":38}],"source":["text_lemmatization('My system keeps crashing! his crashed yesterday, ours crashes daily')"]},{"cell_type":"markdown","source":["### 7 - Stopwords removal"],"metadata":{"id":"O1twRh78HmPz"}},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1719499022617,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"K0IHQcqWj6uI","outputId":"c8186e82-827b-45d5-f3ab-a80123c5c432"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":39}],"source":["nltk.download('stopwords')"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"0EQN7MOsj8VJ","executionInfo":{"status":"ok","timestamp":1719499022617,"user_tz":-330,"elapsed":22,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["from nltk.tokenize.toktok import ToktokTokenizer"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1719499022618,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"8ec_oisFkBf1","outputId":"0b5bd3c5-0f66-4bdd-95d7-310e0c53195a"},"outputs":[{"output_type":"stream","name":"stdout","text":["['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"]}],"source":["tokenizer = ToktokTokenizer()\n","stopword_list = nltk.corpus.stopwords.words('english')\n","print(stopword_list[:10])"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"93rqei12kF7n","executionInfo":{"status":"ok","timestamp":1719499022619,"user_tz":-330,"elapsed":20,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["# 7_ def remove stop words\n","def stopword_removal(tokens):\n","  stopword_list = nltk.corpus.stopwords.words('english')\n","  filtered_tokens = [token for token in tokens if token not in stopword_list]\n","  return filtered_tokens\n","  if is_lower_case:\n","    filtered_tokens = [token for token in tokens if token not in stopword_list]\n","  else:\n","    filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n","  filtered_text =''.join(filtered_tokens)\n","  return filtered_text"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1719499022619,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"t3Xil_aDkPIR","outputId":"e1a20e53-7d64-41af-94ec-ae41d9a12a75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['T',\n"," 'h',\n"," 'e',\n"," ',',\n"," ' ',\n"," 'n',\n"," ',',\n"," ' ',\n"," 'f',\n"," ' ',\n"," 'r',\n"," 'e',\n"," ' ',\n"," 'p',\n"," 'w',\n"," 'r',\n"," ',',\n"," ' ',\n"," 'c',\n"," 'p',\n"," 'u',\n"," 'e',\n"," 'r',\n"," ' ',\n"," ' ',\n"," 'n']"]},"metadata":{},"execution_count":43}],"source":["stopword_removal(\"The, and, if are stopwords, computer is not\")"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"q2Wt8W8ETacI","executionInfo":{"status":"ok","timestamp":1719499022619,"user_tz":-330,"elapsed":17,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["corpus =(\"US unveils world's most powerful supercomputer, beats China. \"\n","\"The US has unveiled the world's most powerful supercomputer called 'Summit', \"\n","\"beating the previous record-holder China's Sunway TaihuLight. With a peak performance \"\n","\"of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, \"\n","\"which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, \"\n","\"which reportedly take up the size of two tennis courts.\")"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1719499022620,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"SMTCnKS_T2G-","outputId":"a61ab198-8a3d-44c6-90c1-1b1c0587f4bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":45}],"source":["corpus"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"EKYkBbFUrbrs","executionInfo":{"status":"ok","timestamp":1719499022620,"user_tz":-330,"elapsed":16,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["from textblob import TextBlob"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"JyyNw0ESpXem","executionInfo":{"status":"ok","timestamp":1719499022620,"user_tz":-330,"elapsed":16,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["def normalize_corpus(corpus,html_stripping=True,contraction_expansion=True,accented_char_removal=True,text_lower_case=True,\n","                     text_lemmatization=True,special_char_removal=True,stopword_removal=True):\n","  normalized_corpus = []\n","  # normalize each document in the corpus\n","  for doc in corpus:\n","    # strip HTML\n","    if html_stripping:\n","      doc = html_stripping(doc)\n","    if contraction_expansion:\n","      doc = contraction_expansion(doc)\n","    if accented_char_removal:\n","      doc = accented_char_removal(doc)\n","    if text_lower_case:\n","      doc = doc.lower()\n","      # remove extra newlines\n","      doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n","    # lemmatize text\n","    if text_lemmatization:\n","      doc = text_lemmatization(doc)\n","    # remove special characters and\\or digits\n","    if special_char_removal:\n","      # insert spaces between special characters to isolate them\n","      special_char_pattern = re.compile(r'([{.(-)!}])')\n","      doc = special_char_pattern.sub(\" \\\\1 \", doc)\n","      doc = special_char_removal(doc, remove_digits=True)\n","      # remove extra whitespace\n","      doc = re.sub(' +', ' ', doc)\n","    # remove stopwords\n","    if stopword_removal:\n","      doc = stopword_removal(doc)\n","      normalized_corpus.append(doc)\n","  return normalized_corpus\n"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6263,"status":"ok","timestamp":1719499028868,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"ndNskOIap0Td","outputId":"aec8a903-2101-47e7-b6df-1e1fee8e56dd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['u'],\n"," [],\n"," [' '],\n"," ['u'],\n"," ['n'],\n"," ['v'],\n"," ['e'],\n"," ['I'],\n"," ['l'],\n"," [],\n"," [' '],\n"," ['w'],\n"," [],\n"," ['r'],\n"," ['l'],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," ['p'],\n"," [],\n"," ['w'],\n"," ['e'],\n"," ['r'],\n"," ['f'],\n"," ['u'],\n"," ['l'],\n"," [' '],\n"," [],\n"," ['u'],\n"," ['p'],\n"," ['e'],\n"," ['r'],\n"," ['c'],\n"," [],\n"," [],\n"," ['p'],\n"," ['u'],\n"," [],\n"," ['e'],\n"," ['r'],\n"," [],\n"," [' '],\n"," ['b'],\n"," ['e'],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," ['c'],\n"," ['h'],\n"," ['I'],\n"," ['n'],\n"," [],\n"," [' '],\n"," [' '],\n"," [],\n"," ['h'],\n"," ['e'],\n"," [' '],\n"," ['u'],\n"," [],\n"," [' '],\n"," ['h'],\n"," [],\n"," [],\n"," [' '],\n"," ['u'],\n"," ['n'],\n"," ['v'],\n"," ['e'],\n"," ['I'],\n"," ['l'],\n"," ['e'],\n"," [],\n"," [' '],\n"," [],\n"," ['h'],\n"," ['e'],\n"," [' '],\n"," ['w'],\n"," [],\n"," ['r'],\n"," ['l'],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," ['p'],\n"," [],\n"," ['w'],\n"," ['e'],\n"," ['r'],\n"," ['f'],\n"," ['u'],\n"," ['l'],\n"," [' '],\n"," [],\n"," ['u'],\n"," ['p'],\n"," ['e'],\n"," ['r'],\n"," ['c'],\n"," [],\n"," [],\n"," ['p'],\n"," ['u'],\n"," [],\n"," ['e'],\n"," ['r'],\n"," [' '],\n"," ['c'],\n"," [],\n"," ['l'],\n"," ['l'],\n"," ['e'],\n"," [],\n"," [' '],\n"," [],\n"," [],\n"," ['u'],\n"," [],\n"," [],\n"," ['I'],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," ['b'],\n"," ['e'],\n"," [],\n"," [],\n"," ['I'],\n"," ['n'],\n"," ['g'],\n"," [' '],\n"," [],\n"," ['h'],\n"," ['e'],\n"," [' '],\n"," ['p'],\n"," ['r'],\n"," ['e'],\n"," ['v'],\n"," ['I'],\n"," [],\n"," ['u'],\n"," [],\n"," [' '],\n"," ['r'],\n"," ['e'],\n"," ['c'],\n"," [],\n"," ['r'],\n"," [],\n"," [],\n"," ['h'],\n"," [],\n"," ['l'],\n"," [],\n"," ['e'],\n"," ['r'],\n"," [' '],\n"," ['c'],\n"," ['h'],\n"," ['I'],\n"," ['n'],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," ['u'],\n"," ['n'],\n"," ['w'],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," [],\n"," ['I'],\n"," ['h'],\n"," ['u'],\n"," ['l'],\n"," ['I'],\n"," ['g'],\n"," ['h'],\n"," [],\n"," [' '],\n"," [' '],\n"," ['w'],\n"," ['I'],\n"," [],\n"," ['h'],\n"," [' '],\n"," [],\n"," [' '],\n"," ['p'],\n"," ['e'],\n"," [],\n"," ['k'],\n"," [' '],\n"," ['p'],\n"," ['e'],\n"," ['r'],\n"," ['f'],\n"," [],\n"," ['r'],\n"," [],\n"," [],\n"," ['n'],\n"," ['c'],\n"," ['e'],\n"," [' '],\n"," [],\n"," ['f'],\n"," [' '],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," ['r'],\n"," ['I'],\n"," ['l'],\n"," ['l'],\n"," ['I'],\n"," [],\n"," ['n'],\n"," [' '],\n"," ['c'],\n"," [],\n"," ['l'],\n"," ['c'],\n"," ['u'],\n"," ['l'],\n"," [],\n"," [],\n"," ['I'],\n"," [],\n"," ['n'],\n"," [],\n"," [' '],\n"," ['p'],\n"," ['e'],\n"," ['r'],\n"," [' '],\n"," [],\n"," ['e'],\n"," ['c'],\n"," [],\n"," ['n'],\n"," [],\n"," [],\n"," [' '],\n"," ['I'],\n"," [],\n"," [' '],\n"," ['I'],\n"," [],\n"," [' '],\n"," [],\n"," ['v'],\n"," ['e'],\n"," ['r'],\n"," [' '],\n"," [],\n"," ['w'],\n"," ['I'],\n"," ['c'],\n"," ['e'],\n"," [' '],\n"," [],\n"," [],\n"," [' '],\n"," ['f'],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," ['u'],\n"," ['n'],\n"," ['w'],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," [],\n"," ['I'],\n"," ['h'],\n"," ['u'],\n"," ['l'],\n"," ['I'],\n"," ['g'],\n"," ['h'],\n"," [],\n"," [],\n"," [' '],\n"," ['w'],\n"," ['h'],\n"," ['I'],\n"," ['c'],\n"," ['h'],\n"," [' '],\n"," ['I'],\n"," [],\n"," [' '],\n"," ['c'],\n"," [],\n"," ['p'],\n"," [],\n"," ['b'],\n"," ['l'],\n"," ['e'],\n"," [' '],\n"," [],\n"," ['f'],\n"," [' '],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," ['r'],\n"," ['I'],\n"," ['l'],\n"," ['l'],\n"," ['I'],\n"," [],\n"," ['n'],\n"," [' '],\n"," ['c'],\n"," [],\n"," ['l'],\n"," ['c'],\n"," ['u'],\n"," ['l'],\n"," [],\n"," [],\n"," ['I'],\n"," [],\n"," ['n'],\n"," [],\n"," [' '],\n"," ['p'],\n"," ['e'],\n"," ['r'],\n"," [' '],\n"," [],\n"," ['e'],\n"," ['c'],\n"," [],\n"," ['n'],\n"," [],\n"," [' '],\n"," [' '],\n"," [],\n"," ['u'],\n"," [],\n"," [],\n"," ['I'],\n"," [],\n"," [' '],\n"," ['h'],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [' '],\n"," [],\n"," ['e'],\n"," ['r'],\n"," ['v'],\n"," ['e'],\n"," ['r'],\n"," [],\n"," [],\n"," [' '],\n"," ['w'],\n"," ['h'],\n"," ['I'],\n"," ['c'],\n"," ['h'],\n"," [' '],\n"," ['r'],\n"," ['e'],\n"," ['p'],\n"," [],\n"," ['r'],\n"," [],\n"," ['e'],\n"," [],\n"," ['l'],\n"," [],\n"," [' '],\n"," [],\n"," [],\n"," ['k'],\n"," ['e'],\n"," [' '],\n"," ['u'],\n"," ['p'],\n"," [' '],\n"," [],\n"," ['h'],\n"," ['e'],\n"," [' '],\n"," [],\n"," ['I'],\n"," ['z'],\n"," ['e'],\n"," [' '],\n"," [],\n"," ['f'],\n"," [' '],\n"," [],\n"," ['w'],\n"," [],\n"," [' '],\n"," [],\n"," ['e'],\n"," ['n'],\n"," ['n'],\n"," ['I'],\n"," [],\n"," [' '],\n"," ['c'],\n"," [],\n"," ['u'],\n"," ['r'],\n"," [],\n"," [],\n"," [' ']]"]},"metadata":{},"execution_count":48}],"source":["normalize_corpus(corpus,html_stripping=html_stripping,contraction_expansion=TextBlob,accented_char_removal=accented_char_removal,text_lower_case=True,text_lemmatization=text_lemmatization,special_char_removal=special_char_removal,stopword_removal=stopword_removal)"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"bw6f_ZI_uhVv","executionInfo":{"status":"ok","timestamp":1719499028868,"user_tz":-330,"elapsed":28,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["def normalize_corpus(corpus):\n","  normalized_corpus = []\n","  for text in corpus:\n","    # 1\n","    text=html_stripping(text)\n","    # 2\n","    text=special_char_removal(text)\n","    # 3\n","    text=contraction_expansion(text,contraction_mapping)\n","    # 4\n","    # text=simple_stemmer(text)\n","    # 5\n","    text=accented_char_removal(text)\n","    # 6\n","    text=text_lemmatization(text)\n","    # 7\n","    text=stopword_removal(text)\n","    normalized_corpus.append(text)\n","    #if tokenize:\n","    #  text = tokenize_text(text)\n","    # normalized_corpus.append(text)\n","  return normalized_corpus"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5742,"status":"ok","timestamp":1719499034584,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"doclljwKxbBx","outputId":"8784b843-bb68-46b5-adf0-1279c5c059f2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e'],\n"," ['n', 'n', 'e']]"]},"metadata":{},"execution_count":50}],"source":["normalize_corpus(corpus)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15947,"status":"ok","timestamp":1719499050509,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"},"user_tz":-330},"id":"quVqkLbir17c","outputId":"98f043cf-25fa-4569-c77b-d155417c3764"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting text_normalizer\n","  Downloading text-normalizer-0.1.3.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from text_normalizer) (2.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->text_normalizer) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->text_normalizer) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->text_normalizer) (2024.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->text_normalizer) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->text_normalizer) (1.16.0)\n","Building wheels for collected packages: text_normalizer\n","  Building wheel for text_normalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for text_normalizer: filename=text_normalizer-0.1.3-cp310-cp310-linux_x86_64.whl size=247447 sha256=a697a2922465181d2d2624e25014054471331b95f34973e0a1ab46759419f3ba\n","  Stored in directory: /root/.cache/pip/wheels/fa/9f/80/4a4e7d2d6f6fc35b19993353c2c8f1f7ac48ac29c826d2e676\n","Successfully built text_normalizer\n","Installing collected packages: text_normalizer\n","Successfully installed text_normalizer-0.1.3\n"]}],"source":["# Install Text Normalizer for extracting the newsgoup data set\n","!pip install text_normalizer"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"DPt2BLsNlQbf","executionInfo":{"status":"ok","timestamp":1719499050510,"user_tz":-330,"elapsed":11,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["import text_normalizer"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"QPUWf7fDMWhL","executionInfo":{"status":"ok","timestamp":1719499050510,"user_tz":-330,"elapsed":9,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["from sklearn.datasets import fetch_20newsgroups"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"Pfu510qpMgJn","executionInfo":{"status":"ok","timestamp":1719499051647,"user_tz":-330,"elapsed":1145,"user":{"displayName":"Arya Talekar","userId":"08764980960273992459"}}},"outputs":[],"source":["# Create objects for each package\n","import numpy as np\n","#import text_normalizer as tn\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"code","source":["import time\n","from sklearn.datasets import fetch_20newsgroups\n","\n","# Wait for 60 seconds before trying again\n","time.sleep(60)\n","\n","# Fetch data\n","data = fetch_20newsgroups(subset='all')\n","data = fetch_20newsgroups(subset='all', shuffle=True, remove=('headers', 'footers', 'quotes'))\n","data_labels_map = dict(enumerate(data.target_names))\n","\n","print(\"Dataset fetched successfully!\")"],"metadata":{"id":"O1v_S5jlNiT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-82brBxgsL9"},"outputs":[],"source":["# building the dataframe for the data extracted from newgroups\n","# Create a corpus of newsgroup sentences\n","corpus=data.data\n","target_labels=data.target\n","target_names = [data_labels_map[label] for label in data.target]\n","data_df = pd.DataFrame({'Article': corpus, 'Target Label': target_labels,'Target Name': target_names})\n","print(data_df.shape)\n","data_df.head(30)"]},{"cell_type":"markdown","metadata":{"id":"pfMDTvZbkH1f"},"source":["From this dataset, we can see that each document has some textual content and the\n","label can be denoted by a specific number, which maps to a newsgroup category name"]}],"metadata":{"colab":{"provenance":[{"file_id":"1iSMNNBUrGW_8WNlJLw8SUN3IStQEpuW_","timestamp":1708500891155}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}